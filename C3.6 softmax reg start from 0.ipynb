{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104dcb64-0bb1-4a3b-b7bb-5e36bd5cfe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import sys\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c16c3-6487-492c-9ec5-13eece1880c1",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de622eb3-9e14-42d9-bd23-32597ccba072",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f097768-ca95-4c21-b016-5a0f48a8942a",
   "metadata": {},
   "source": [
    "#### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec78c331-0977-4a53-b578-f3816d0ab643",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs))).to(torch.float32)\n",
    "b = torch.zeros(num_outputs, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0813a11a-78ea-4b52-a899-ab068d825d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开模型参数梯度\n",
    "W.requires_grad_(True);\n",
    "b.requires_grad_(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1a358-04df-4ec7-adcd-64884af8dfdc",
   "metadata": {},
   "source": [
    "#### 定义Softmax函数<br>\n",
    "$$\n",
    "Softmax(x)=(\\frac{e^{x_1}}{\\sum_{i=1}^{n}{e^{x_i}}},\\frac{e^{x_2}}{\\sum_{i=1}^{n}{e^{x_i}}},...,\\frac{e^{x_n}}{\\sum_{i=1}^{n}{e^{x_i}}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ffedf1-4547-4b77-93c0-fe6734549bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    return X_exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e27a5d-3fae-4037-8f55-dd026c8c876b",
   "metadata": {},
   "source": [
    "#### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b060693a-c0c5-433c-a4f3-a898d47c359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5fdc7-6dd7-4b34-98f4-bb8deb6b336f",
   "metadata": {},
   "source": [
    "#### 定义损失函数\n",
    "**交叉熵损失函数**<br>\n",
    "$$\n",
    "H(y,\\hat{y})=-\\log{\\hat{y}_{i}},\\,where\\,y_i==1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98fd9ade-7af9-4456-ab10-d4cfc68dbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat,y):\n",
    "    ''''\n",
    "    input:\n",
    "    y_hat:nxm matrics float 0<=y_hat<=1\n",
    "    y    :mx1 vector int 0<=y<=m\n",
    "    output:\n",
    "    the prescision: nx1 matrics float\n",
    "    '''\n",
    "    return -torch.log(y_hat.gather(1, y.view(-1,1)))\n",
    "# gather用法：\n",
    "# torch.gather(a,axis,b) or a.gather(axis,b)\n",
    "# a为原始张量，b为按照axis轴索引值\n",
    "# 返回一个b形状的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ff2f7-b8a2-4cf7-8546-c3dcece74a87",
   "metadata": {},
   "source": [
    "#### 计算分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff3267c-9752-4c86-98ff-8fae3ffee523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1)==y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da27192a-df46-4903-a1d3-ee4f4b59ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac366c1f-d66a-427b-8102-6ab3704cae19",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3bd9214-5a69-430d-8f54-417419a594be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d82e1197-6a3d-4b24-96e8-50a02ea687bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr = 5, 0.1\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None,lr=None,optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n+=y.shape[0]\n",
    "            \n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b600d1e-0da0-4b76-8f62-d64e230e925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.5705, train acc 0.813, test acc 0.809\n",
      "epoch 2, loss 0.5262, train acc 0.826, test acc 0.818\n",
      "epoch 3, loss 0.5025, train acc 0.832, test acc 0.823\n",
      "epoch 4, loss 0.4858, train acc 0.837, test acc 0.827\n",
      "epoch 5, loss 0.4740, train acc 0.839, test acc 0.828\n"
     ]
    }
   ],
   "source": [
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda33631-6bf2-4890-8af4-5237260ca1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
