{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f22a87-1238-4a6a-a77c-876915ea9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c08acc-e95c-44ea-8851-64cd9dbd60b2",
   "metadata": {},
   "source": [
    "## Torch自带数据集加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba240a2-1788-41a8-942b-861eef704827",
   "metadata": {},
   "source": [
    "#### FashionMNIST\n",
    "以此为例，其他类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "34f5d5dd-abe4-40b6-b57c-80bd407bae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offical_exist_data(data_name='FashionMNIST', batch_size=256, path='../../../Datasets/FashionMNIST'):\n",
    "    if data_name == 'FashionMNIST':\n",
    "        train = torchvision.datasets.FashionMNIST(root=path,train=True,download=True,\n",
    "                                              transform=transforms.ToTensor())\n",
    "        test = torchvision.datasets.FashionMNIST(root=path,train=False,download=True,\n",
    "                                              transform=transforms.ToTensor())\n",
    "    # elif ...\n",
    "    # ...\n",
    "    \n",
    "    train_iter = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "42562b68-9741-4c56-8aa5-dbea5e4c98a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, test_iter = offical_exist_data()\n",
    "for x,y in train_iter:\n",
    "    break\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbe089-b3ad-4ce1-bab6-31c5d16f03e1",
   "metadata": {},
   "source": [
    "## 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4437bec1-9d33-4926-a75c-45ee216fc289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.Tensor(self.features[index])\n",
    "        label = torch.LongTensor(self.labels[index])\n",
    "        return feature, label\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda61ce-6dbc-46bf-b335-3fe41dcd4b83",
   "metadata": {},
   "source": [
    "#### 加载内存中的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0329467-4912-497d-b0f4-d900e4cef2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.random.random((10,10))\n",
    "label = np.random.randint(0,10,(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7410f109-7604-483e-9c7c-9ed56691be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Datasets(feature,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97bbefd5-43f4-4ddf-9716-0f9cf9822608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.6762, 0.2933, 0.2260, 0.3678, 0.7459, 0.5180, 0.0798, 0.8472, 0.9283,\n",
      "        0.2913]), tensor([2]))\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f2bd3-f96d-4bc8-b9b9-08380c823266",
   "metadata": {},
   "source": [
    "#### 加载本地图像数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b7dd2b0a-7669-410f-9689-361e759072f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(id_labels=[], cls_labels=[],data_path='../Datasets/data1'):\n",
    "    '''\n",
    "    this function can map label's id to class name as well as class name to label's id \n",
    "    '''\n",
    "    cls_list = os.listdir(data_path)\n",
    "    id_name=list(range(len(cls_list)))\n",
    "    cls_name=cls_list\n",
    "    if cls_labels == []:\n",
    "        return [cls_name[int(i)] for i in id_labels]\n",
    "    elif id_labels == []:\n",
    "        return list(map(cls_name.index,cls_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e322872e-f440-4538-bc7b-969925a3c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_data(data_path = '../Datasets/data1', img_size=(28,28), img_type='L'):\n",
    "    '''\n",
    "    data folder tree:\n",
    "        data1:\n",
    "            class(0):\n",
    "                image1\n",
    "                image2\n",
    "                ...\n",
    "            class(1):\n",
    "                image1\n",
    "                image2\n",
    "                ...\n",
    "            ...\n",
    "            class(n):\n",
    "                ...\n",
    "                \n",
    "    img_size: HxW int\n",
    "    img_type: \n",
    "        use to convert image by PIL.Image.convert() function\n",
    "        options:\n",
    "            'L': gray\n",
    "            'RGB': 3-channel image\n",
    "    '''\n",
    "    # class name list\n",
    "    cls_list = os.listdir(data_path)\n",
    "    # all files' names\n",
    "    all_cls_files = []\n",
    "    for i in range(len(cls_list)):\n",
    "        all_cls_files.append(os.listdir(os.path.join(data_path, cls_list[i])))\n",
    "    # all files' paths\n",
    "    all_feature_path = []\n",
    "    for cls_i in range(len(all_cls_files)):\n",
    "        for feature_i in range(len(all_cls_files[cls_i])):\n",
    "            all_feature_path.append(os.path.join(data_path, cls_list[cls_i], all_cls_files[cls_i][feature_i]))\n",
    "    #### handle features ####\n",
    "    # use PIL load image data [0-255] RGB HxWxC\n",
    "    features_PIL=[]\n",
    "    for path in all_feature_path:\n",
    "        img = Image.open(path)\n",
    "        # convert to img_type\n",
    "        img = img.convert(img_type)\n",
    "        # resize image\n",
    "        img = img.resize(img_size,Image.ANTIALIAS)#  Image.ANTIALIAS 最高质量\n",
    "        features_PIL.append(img)\n",
    "    # transform to Tensor [0,1]\n",
    "    ToTensor = transforms.ToTensor()\n",
    "    features = list()\n",
    "    for feature in features_PIL:\n",
    "        features.append(ToTensor(feature))\n",
    "    features = torch.stack(features,0)\n",
    "    #### handle labels ####\n",
    "    # load labels\n",
    "    cls_label = []\n",
    "    for i in range(len(cls_list)):\n",
    "        cls_name = []\n",
    "        cls_name.append(cls_list[i])\n",
    "        cls_label += (cls_name*len(all_cls_files[i]))\n",
    "    # if not LongTensor will get some bugs...\n",
    "    id_label = torch.LongTensor(label_map(cls_labels=cls_label))\n",
    "    \n",
    "    return features, id_label, cls_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "876bc938-25c3-46c2-bbd2-8504c83877dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, id_label, cls_label = load_local_data(data_path = '../Datasets/data1', img_size=(28,28))\n",
    "data = Datasets(features,id_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "52252077-161d-429f-b471-c54f020e803b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 28, 28])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa96851-b82c-4e57-9750-8e1041f4dfdc",
   "metadata": {},
   "source": [
    "#### 打乱数据并分割训练集验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9210b33-807a-48f0-a05f-20341b446cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(feature,label,split_scale=0.7):\n",
    "    index = np.arange(features.shape[0])\n",
    "    np.random.shuffle(index)\n",
    "    train_index = index[:int(len(index)*split_scale)]\n",
    "    test_index = index[int(len(index)*split_scale):]\n",
    "    train_feature = feature[train_index]\n",
    "    test_feature = feature[test_index]\n",
    "    train_label = label[train_index]\n",
    "    test_label = label[test_index]\n",
    "    return train_feature,test_feature,train_label,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "88e2c3ec-08c9-48c8-b8f6-607df0159faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature,test_feature,train_label,test_label = train_test_split(features,id_label,1)\n",
    "train_data = Datasets(train_feature, train_label)\n",
    "test_data = Datasets(test_feature, test_label)\n",
    "batch_size = 256\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "#test_iter = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f336f726-aa8c-4d2f-8e38-a59787eab9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 1, 28, 28))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "29600c86-d5d2-42bc-b5e3-34b3c35b9bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0039, 0.0000,  ..., 0.9255, 0.4824, 0.0078],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.4118, 0.0275, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 0.9961,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.9961, 0.9922, 0.9804,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 0.9961,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c1662-9096-4717-9547-b19731a3ab20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
