{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70893d0c-039a-440f-9d89-dd1050923f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425887ed-2c92-479e-bb9a-ec097fdfd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527047e-d37c-4467-bed9-a3731dfe82be",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba44183-010d-46ae-a80b-f3b6b0779f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e514a1-7bdc-472e-852d-6d92c0d1709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x.view(x.shape[0], -1))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3554155-4eee-4909-aa80-b3e25f326eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# 定义形状转换功能\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "# 模型2\n",
    "from collections import OrderedDict\n",
    "\n",
    "net = nn.Sequential(\n",
    "    OrderedDict([('flatten', FlattenLayer()),\n",
    "                 ('linear', nn.Linear(num_inputs, num_outputs))\n",
    "                ])\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54173d7c-12dc-434b-91ca-f76a736a78d0",
   "metadata": {},
   "source": [
    "**初始化参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8052bf55-4df8-4a29-8083-e8c675bfef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init.normal_(net.linear.weight, mean=0, std=0.01);\n",
    "init.constant_(net.linear.bias, val=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69142436-112a-4355-889b-b272d987fc1f",
   "metadata": {},
   "source": [
    "**softmax与交叉熵损失函数**<br>\n",
    "由于softmax与交叉熵损失函数分开定义可能会导致数值不稳定https://blog.csdn.net/Shingle_/article/details/81988628<br>\n",
    "因此，pytorch提供了一个同时包含softmax计算以及交叉熵损失计算的函数，提升了数值稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced10324-5858-4729-9295-4d4342cefacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e30f2e-9f99-468c-acd2-d4b9c74384b5",
   "metadata": {},
   "source": [
    "**定义优化算法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50bb4ee0-59c3-469d-9a99-e7de8b9e5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374a5b8-698b-412e-bc00-cc5db94da045",
   "metadata": {},
   "source": [
    "**训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0239f9-e8c6-4c20-ad1d-df34b917c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ed195a-8f8e-4e4a-8945-424c48d6603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0022, train acc 0.813, test acc 0.811\n",
      "epoch 2, loss 0.0021, train acc 0.825, test acc 0.818\n",
      "epoch 3, loss 0.0020, train acc 0.832, test acc 0.821\n",
      "epoch 4, loss 0.0019, train acc 0.837, test acc 0.825\n",
      "epoch 5, loss 0.0019, train acc 0.839, test acc 0.827\n",
      "epoch 6, loss 0.0018, train acc 0.843, test acc 0.826\n",
      "epoch 7, loss 0.0018, train acc 0.844, test acc 0.828\n",
      "epoch 8, loss 0.0018, train acc 0.846, test acc 0.817\n",
      "epoch 9, loss 0.0018, train acc 0.848, test acc 0.833\n",
      "epoch 10, loss 0.0017, train acc 0.850, test acc 0.830\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_l_sum, train_acc_sum, n = 0, 0, 0\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y).sum()\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        train_l_sum += l.item()\n",
    "        train_acc_sum += (y_hat.argmax(dim=1)==y).sum().item()\n",
    "        n+=y.shape[0]\n",
    "    test_acc = evaluate_accuracy(test_iter, net)\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d74d1-5a06-4e37-b6da-4fe4c280517b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
